{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "JXjadZQsq18S"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "__rDTwkCq-CF"
      },
      "outputs": [],
      "source": [
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "reVd-acUrG3h"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms, datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIv5V33yrdd5",
        "outputId": "cf41776d-74c8-4093-d61e-d0c40bb1e0fe"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "train = datasets.MNIST(\"\", train = True, download = True,\n",
        "                       transform= transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "test = datasets.MNIST(\"\", train = False, download = True,\n",
        "                       transform= transforms.Compose([transforms.ToTensor()]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data importation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "DRDPbpcXtig8"
      },
      "outputs": [],
      "source": [
        "\n",
        "trainset = torch.utils.data.DataLoader(train, batch_size=16,shuffle= True) # batch_siez is between 8 and 64\n",
        "\n",
        "\n",
        "testset = torch.utils.data.DataLoader(test , batch_size=16,shuffle= True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bvr_VD8vZ3V",
        "outputId": "9d89dcb1-cab5-42be-fcb4-141d451e1899"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([0, 7, 4, 2, 1, 7, 5, 5, 4, 0, 9, 3, 1, 2, 7, 4])]\n"
          ]
        }
      ],
      "source": [
        "for data in trainset :\n",
        "  print (data)\n",
        "  break # 1 batch of 10 random samples of the dataset, and the tensor of ther values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iUMDOvwvotB",
        "outputId": "ae089bd9-7b19-49ad-9aba-b94e9e1222de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0)\n"
          ]
        }
      ],
      "source": [
        "# in the for loop, the last temporary variable that is used can still be accesed\n",
        "\n",
        "#here, data is a tesor of tensor images and a tensor of tensor for your values\n",
        "\n",
        "\n",
        "x,y = data[0][0], data[1][0]\n",
        "\n",
        "print (y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "zXy78RqSxNpA",
        "outputId": "3f10042a-ee40-46cf-eb9f-8e1f8f106e8f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(data[0][0].view(28, 28))\n",
        "#puisque torch.Size([1, 28, 28]) n'est pas une taille valide pour plt\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWKJ9M9jxfCR",
        "outputId": "89edb34d-e705-4886-c4fc-3902afa426cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puSQwzwzyZ9A"
      },
      "source": [
        "What is Balancing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayW4FW1Kyd0z",
        "outputId": "9502e9c9-d38b-45e2-add3-0848c22e0492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
            "{0: 9.871666666666666, 1: 11.236666666666666, 2: 9.93, 3: 10.218333333333334, 4: 9.736666666666666, 5: 9.035, 6: 9.863333333333333, 7: 10.441666666666666, 8: 9.751666666666667, 9: 9.915000000000001}\n"
          ]
        }
      ],
      "source": [
        "conter_dict = {0 : 0, 1 : 0, 2 : 0, 3 : 0,4 : 0,5 : 0,6 : 0, 7 : 0, 8 : 0, 9 : 0}\n",
        "total = 0\n",
        "for data in trainset:\n",
        "  Xs, Ys = data\n",
        "  for y in Ys:\n",
        "    conter_dict[int(y)] +=1\n",
        "    total+=1\n",
        "\n",
        "print (conter_dict)\n",
        "for k in range (10):\n",
        "  conter_dict[int(k)] = (conter_dict[int(k)]/total)*100\n",
        "\n",
        "print(conter_dict)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "P9sV9aBq8f8K"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Building the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #fc = fully connected, 1 = first layer\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(28*28, 64)\n",
        "        self.fc1 = nn.Linear(28*28, 64) \n",
        "        self.fc2 = nn.Linear(64, 64) \n",
        "        self.fc3 = nn.Linear(64, 64) \n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        \n",
        "        x = F.relu(self.fc1(x)) #relu = rectified linear --> activation fction\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)#we need a O to 1 output in this tensor so we use log_sofmax\n",
        "        return F.log_softmax(x, dim = 1) # dim = 0 is the batches i think\n",
        "    \n",
        "\n",
        "net = Net()\n",
        "print(net)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[7.0517e-02, 9.2440e-01, 6.6551e-01, 1.3533e-01, 9.5665e-01, 3.8836e-01,\n",
            "         1.3881e-01, 8.8262e-01, 3.0298e-01, 4.5895e-01, 3.2266e-01, 5.4260e-02,\n",
            "         1.1087e-01, 4.0233e-01, 4.8079e-01, 9.6573e-02, 8.7300e-01, 7.7284e-01,\n",
            "         9.9251e-01, 9.5581e-01, 6.4834e-01, 7.8703e-01, 3.6018e-01, 2.1797e-01,\n",
            "         3.0999e-02, 6.4150e-01, 9.7308e-01, 7.1518e-01],\n",
            "        [1.6574e-01, 3.8210e-01, 1.1683e-01, 4.6744e-01, 8.8508e-01, 6.3090e-01,\n",
            "         1.3796e-01, 8.5603e-01, 5.9820e-01, 4.3377e-01, 6.5585e-01, 6.8809e-01,\n",
            "         9.6480e-01, 8.6875e-01, 4.5920e-01, 1.9207e-01, 7.2000e-01, 3.2572e-01,\n",
            "         8.1097e-01, 4.3137e-01, 8.4980e-01, 8.5564e-01, 6.4562e-01, 5.9223e-01,\n",
            "         4.8581e-01, 4.5620e-01, 9.8457e-01, 4.3082e-01],\n",
            "        [3.7003e-01, 6.1354e-01, 9.1135e-01, 6.1050e-01, 6.1965e-01, 2.1372e-01,\n",
            "         6.4841e-02, 4.1302e-01, 2.2089e-01, 4.3611e-01, 5.5208e-01, 9.2542e-01,\n",
            "         2.9879e-02, 7.0746e-01, 6.7256e-02, 2.4518e-01, 1.3297e-01, 3.1845e-01,\n",
            "         3.4164e-01, 3.4947e-01, 4.2741e-01, 1.0530e-01, 5.9718e-01, 4.2653e-01,\n",
            "         7.7686e-01, 7.3871e-01, 1.2053e-02, 1.9695e-02],\n",
            "        [4.0056e-01, 3.5480e-01, 6.4467e-01, 6.5022e-01, 6.4592e-01, 8.9614e-03,\n",
            "         6.8863e-01, 2.2017e-02, 7.7192e-02, 3.5551e-01, 2.6368e-01, 6.4401e-01,\n",
            "         2.8338e-01, 7.3407e-01, 3.9510e-01, 1.7176e-01, 8.9430e-01, 6.6148e-01,\n",
            "         7.9229e-01, 4.2176e-02, 8.8268e-01, 2.4887e-01, 2.9131e-01, 2.9627e-01,\n",
            "         7.3578e-01, 4.8991e-01, 9.4197e-01, 1.3178e-01],\n",
            "        [8.4472e-01, 4.6786e-01, 6.5502e-01, 9.1035e-01, 2.9265e-01, 8.0179e-02,\n",
            "         3.5573e-01, 8.4045e-02, 5.4733e-01, 2.0133e-01, 6.5713e-01, 1.5471e-01,\n",
            "         9.7009e-02, 5.3922e-01, 5.4591e-01, 7.1369e-01, 6.2360e-01, 2.6990e-01,\n",
            "         9.5755e-01, 4.8693e-01, 7.4688e-01, 2.7597e-02, 3.4398e-01, 8.0292e-01,\n",
            "         5.4359e-01, 4.8057e-01, 9.6682e-01, 3.8501e-01],\n",
            "        [6.6910e-01, 5.6192e-01, 6.2431e-01, 7.5253e-01, 5.9139e-01, 3.5062e-01,\n",
            "         9.4907e-01, 1.1489e-01, 3.8891e-01, 4.3927e-01, 3.4617e-01, 4.2220e-01,\n",
            "         8.4486e-01, 1.3544e-01, 4.5655e-01, 5.2285e-01, 7.7791e-01, 5.3562e-01,\n",
            "         7.2025e-01, 6.4627e-01, 4.5939e-01, 1.6615e-01, 3.8962e-01, 8.3731e-01,\n",
            "         3.3873e-01, 5.8074e-01, 2.6423e-01, 3.4250e-01],\n",
            "        [8.1927e-01, 9.4597e-01, 7.4254e-01, 4.1790e-01, 8.1378e-02, 3.0896e-01,\n",
            "         1.2782e-01, 2.5424e-01, 7.1910e-01, 6.7171e-01, 8.0200e-01, 7.3096e-01,\n",
            "         9.9101e-01, 2.4526e-01, 4.8656e-01, 5.2914e-01, 4.5488e-01, 9.3133e-01,\n",
            "         6.6501e-01, 4.6326e-01, 5.3168e-01, 4.9993e-02, 5.2297e-01, 2.5589e-01,\n",
            "         1.8122e-01, 7.4764e-01, 7.6348e-01, 6.1161e-02],\n",
            "        [5.5509e-01, 3.5962e-02, 3.9193e-01, 1.1985e-01, 4.2367e-01, 3.4301e-01,\n",
            "         8.8868e-01, 1.2232e-01, 7.8121e-01, 9.5907e-02, 6.4017e-01, 7.4441e-01,\n",
            "         8.2919e-01, 7.1817e-01, 6.2918e-01, 9.3492e-01, 5.7830e-01, 7.7143e-01,\n",
            "         3.1858e-01, 3.6758e-01, 7.4529e-01, 4.2013e-01, 1.6246e-02, 9.3091e-02,\n",
            "         8.7578e-02, 7.1360e-02, 4.1504e-01, 5.7898e-01],\n",
            "        [7.8893e-02, 2.7295e-01, 9.0100e-01, 2.3425e-01, 2.1510e-01, 1.0652e-02,\n",
            "         8.6874e-01, 4.8789e-01, 8.3466e-01, 2.8372e-01, 2.7394e-01, 9.4305e-01,\n",
            "         2.7468e-01, 8.3762e-01, 7.0013e-01, 5.7366e-01, 3.4089e-01, 3.0560e-01,\n",
            "         2.3383e-01, 4.9261e-01, 6.3650e-01, 7.3560e-01, 5.3855e-01, 5.3443e-01,\n",
            "         4.5174e-01, 9.7309e-01, 4.4243e-01, 3.8562e-01],\n",
            "        [8.7068e-01, 7.5076e-01, 2.3922e-01, 8.2342e-01, 3.1102e-01, 1.2404e-01,\n",
            "         5.6169e-01, 7.3082e-01, 8.8779e-01, 2.2573e-01, 9.3050e-01, 6.7316e-01,\n",
            "         2.2353e-01, 2.2926e-01, 4.5607e-01, 9.7495e-01, 2.0871e-02, 5.7795e-01,\n",
            "         8.9613e-02, 1.0532e-01, 1.6668e-01, 7.3656e-02, 4.4111e-01, 1.0098e-01,\n",
            "         5.8373e-01, 2.2911e-02, 2.4139e-01, 8.1304e-01],\n",
            "        [6.4186e-01, 2.4909e-01, 8.7959e-01, 1.1179e-02, 5.5572e-01, 8.5461e-01,\n",
            "         8.2241e-01, 5.4632e-01, 5.7056e-01, 3.9882e-01, 1.3884e-01, 2.3055e-01,\n",
            "         1.8930e-01, 6.0980e-01, 1.2889e-01, 4.1993e-01, 2.7556e-01, 6.8060e-01,\n",
            "         7.4565e-01, 7.5723e-01, 1.3701e-01, 8.2952e-01, 4.9904e-01, 9.4650e-01,\n",
            "         6.3836e-01, 3.1897e-01, 4.4763e-01, 5.0555e-01],\n",
            "        [3.0008e-01, 8.6776e-01, 9.1447e-01, 6.1727e-01, 7.8168e-01, 5.2397e-01,\n",
            "         8.5319e-01, 9.4832e-01, 6.8743e-02, 3.4629e-01, 8.4596e-01, 1.0221e-02,\n",
            "         1.7457e-01, 9.6072e-01, 1.1316e-01, 1.4034e-01, 5.6801e-01, 1.4905e-01,\n",
            "         6.5799e-01, 8.7810e-01, 2.2364e-01, 8.7194e-01, 9.7374e-01, 3.5501e-01,\n",
            "         6.5860e-02, 4.2010e-01, 7.3099e-01, 4.2135e-02],\n",
            "        [1.3322e-01, 2.6573e-01, 7.0346e-02, 9.8925e-01, 1.6535e-01, 5.4007e-02,\n",
            "         1.8099e-01, 8.2302e-01, 2.6333e-01, 3.4111e-01, 2.2545e-01, 7.4933e-01,\n",
            "         3.0574e-01, 5.7328e-01, 9.2564e-01, 7.8592e-01, 7.1934e-02, 6.7006e-01,\n",
            "         6.1068e-01, 5.9306e-01, 9.7615e-01, 3.4447e-01, 7.8643e-02, 2.1296e-01,\n",
            "         3.5524e-01, 2.6008e-01, 7.5217e-02, 5.5277e-01],\n",
            "        [9.9593e-01, 4.1226e-01, 8.7502e-01, 8.0063e-02, 4.0285e-01, 7.3490e-01,\n",
            "         3.7836e-01, 8.5450e-01, 8.8922e-01, 7.1923e-01, 2.4048e-01, 3.0071e-01,\n",
            "         2.6411e-02, 2.1135e-01, 8.1494e-01, 4.8778e-01, 3.4274e-01, 5.3523e-01,\n",
            "         1.2252e-01, 3.8297e-01, 1.6842e-01, 2.0958e-01, 6.1598e-01, 6.3819e-01,\n",
            "         3.1128e-01, 9.1271e-01, 1.5596e-01, 1.3658e-01],\n",
            "        [1.9362e-01, 4.0850e-01, 8.0377e-01, 2.2064e-01, 7.5267e-01, 9.8393e-01,\n",
            "         2.6448e-01, 5.3357e-01, 4.8963e-01, 2.6131e-02, 7.8703e-01, 2.3435e-01,\n",
            "         5.1455e-01, 4.3038e-01, 4.1226e-01, 8.7829e-01, 5.6282e-01, 6.2779e-01,\n",
            "         5.2807e-01, 7.7863e-01, 4.8146e-02, 1.9225e-01, 9.4461e-01, 1.6989e-01,\n",
            "         9.7514e-01, 4.6449e-02, 8.7911e-02, 4.7208e-01],\n",
            "        [5.3911e-01, 2.1495e-01, 2.4591e-01, 4.7061e-01, 1.1795e-01, 7.1445e-01,\n",
            "         8.2833e-01, 4.3893e-01, 4.1927e-01, 5.7412e-01, 8.1120e-01, 2.8840e-01,\n",
            "         4.6760e-02, 8.2164e-01, 3.7019e-01, 4.2349e-01, 6.0667e-01, 2.1314e-01,\n",
            "         7.9963e-01, 6.8525e-01, 9.4293e-01, 7.4631e-01, 7.6284e-01, 5.9441e-01,\n",
            "         6.3240e-01, 6.6487e-01, 1.2585e-01, 5.6414e-01],\n",
            "        [6.5747e-01, 2.3483e-01, 6.0360e-01, 3.9030e-01, 5.2237e-01, 4.3660e-01,\n",
            "         2.2192e-01, 9.7125e-01, 3.2303e-01, 9.2523e-01, 1.3319e-01, 4.9985e-02,\n",
            "         1.8657e-01, 6.0604e-01, 2.5748e-01, 7.8304e-01, 6.9369e-01, 7.3518e-01,\n",
            "         5.8199e-01, 8.1803e-01, 6.6657e-02, 3.6858e-01, 8.9773e-01, 5.9690e-01,\n",
            "         2.4855e-01, 3.2363e-01, 8.9303e-01, 1.9690e-01],\n",
            "        [1.5787e-01, 2.0266e-02, 9.4567e-01, 4.1526e-01, 5.2638e-01, 7.7860e-01,\n",
            "         4.1811e-02, 9.0878e-01, 4.1391e-01, 3.5762e-01, 9.4278e-01, 2.8567e-01,\n",
            "         9.3254e-01, 4.1229e-01, 5.6666e-01, 3.3109e-02, 3.6263e-01, 6.2864e-01,\n",
            "         5.4273e-01, 4.4613e-01, 6.3092e-01, 3.2960e-01, 8.7501e-01, 5.6505e-01,\n",
            "         6.5400e-01, 4.1478e-01, 5.9147e-01, 9.6172e-01],\n",
            "        [1.1682e-01, 7.5584e-01, 8.3227e-01, 4.5942e-01, 2.7993e-01, 3.2042e-01,\n",
            "         8.7257e-01, 1.5055e-01, 6.3040e-01, 4.0461e-01, 3.4787e-01, 8.3384e-01,\n",
            "         3.6707e-02, 7.4068e-01, 5.4977e-01, 9.4196e-01, 3.1804e-01, 9.9689e-01,\n",
            "         6.8289e-01, 8.2149e-01, 3.9346e-01, 3.0039e-01, 9.0099e-02, 8.6937e-01,\n",
            "         4.8883e-01, 3.2641e-02, 6.1712e-02, 7.9417e-01],\n",
            "        [5.1566e-01, 7.7498e-02, 7.9173e-01, 2.2223e-01, 6.1806e-01, 3.2818e-01,\n",
            "         1.0104e-01, 2.4566e-01, 9.6773e-01, 1.9680e-02, 3.1953e-02, 7.2499e-01,\n",
            "         6.3374e-01, 4.4698e-01, 3.0989e-01, 4.1029e-01, 1.1120e-01, 1.6901e-02,\n",
            "         8.2638e-01, 6.5761e-01, 3.7416e-01, 9.8913e-01, 4.0783e-01, 5.1144e-01,\n",
            "         5.4609e-02, 8.1588e-01, 3.0810e-01, 7.7670e-01],\n",
            "        [1.6232e-01, 8.1369e-01, 4.3353e-01, 1.6620e-01, 1.5807e-02, 6.4666e-01,\n",
            "         8.4294e-01, 5.9385e-01, 5.6820e-01, 8.2616e-02, 6.6225e-01, 1.6544e-01,\n",
            "         4.4235e-01, 7.4546e-01, 9.5443e-01, 5.5777e-01, 2.7060e-01, 5.8098e-01,\n",
            "         2.5789e-02, 8.1001e-01, 2.8132e-02, 3.7058e-01, 1.3820e-01, 8.5645e-01,\n",
            "         6.3678e-01, 7.4857e-01, 1.8465e-01, 1.9994e-01],\n",
            "        [7.4793e-02, 2.7430e-01, 1.7263e-01, 5.4449e-01, 8.9273e-01, 4.5602e-03,\n",
            "         5.0568e-01, 7.3400e-01, 4.5703e-01, 4.5457e-02, 1.1948e-01, 2.0072e-01,\n",
            "         4.9646e-01, 8.4346e-01, 5.3195e-01, 7.3314e-01, 8.9492e-01, 2.0656e-01,\n",
            "         7.9733e-01, 9.6806e-01, 4.5628e-01, 3.3385e-01, 9.7200e-01, 8.6308e-01,\n",
            "         7.1422e-01, 6.1678e-02, 1.8791e-02, 8.5851e-01],\n",
            "        [3.1571e-01, 3.7185e-01, 2.0916e-01, 2.6036e-02, 5.6065e-01, 9.3597e-03,\n",
            "         4.3956e-01, 5.2371e-01, 2.3755e-01, 5.1104e-03, 1.0220e-01, 6.0359e-01,\n",
            "         9.7186e-01, 8.2604e-01, 7.2974e-01, 9.5898e-01, 9.4350e-01, 9.5541e-01,\n",
            "         4.8732e-02, 1.6354e-01, 9.8865e-01, 1.7627e-01, 7.7221e-01, 2.7633e-01,\n",
            "         9.3397e-01, 6.6591e-02, 8.3596e-01, 8.2500e-01],\n",
            "        [9.1829e-01, 6.7885e-01, 7.1122e-01, 6.3885e-01, 5.1476e-01, 9.7691e-01,\n",
            "         3.0693e-01, 3.5597e-01, 8.5357e-01, 4.7780e-01, 7.2014e-01, 9.3780e-01,\n",
            "         1.3109e-01, 9.5709e-01, 6.0919e-01, 7.4868e-01, 7.0959e-02, 3.2846e-01,\n",
            "         5.0823e-01, 1.7151e-01, 3.0267e-01, 5.7372e-01, 6.7788e-01, 7.7858e-01,\n",
            "         7.2062e-01, 6.5100e-01, 1.3738e-01, 2.4227e-02],\n",
            "        [7.2400e-01, 1.3606e-01, 3.7085e-01, 2.1495e-01, 6.8846e-01, 2.1524e-01,\n",
            "         8.3607e-01, 5.7227e-01, 9.2069e-01, 3.2434e-01, 8.7129e-02, 8.3502e-01,\n",
            "         2.5764e-01, 9.5848e-01, 8.5143e-01, 8.3914e-01, 6.8257e-01, 3.6811e-01,\n",
            "         6.9027e-01, 3.7573e-01, 2.1662e-01, 9.2963e-01, 7.9607e-01, 3.6676e-01,\n",
            "         2.1243e-02, 4.9956e-01, 3.7242e-02, 6.7016e-01],\n",
            "        [5.0455e-01, 6.7770e-01, 9.9778e-01, 2.5875e-01, 3.7785e-01, 9.0353e-01,\n",
            "         9.6896e-01, 4.1963e-01, 1.6397e-01, 1.6954e-01, 7.9719e-01, 3.8768e-01,\n",
            "         7.9514e-01, 2.2917e-02, 4.5523e-02, 7.0090e-01, 7.6873e-01, 1.6503e-01,\n",
            "         5.6049e-02, 7.8993e-01, 6.1799e-01, 8.8567e-01, 3.1664e-01, 8.4906e-01,\n",
            "         8.2120e-01, 9.9331e-01, 8.3828e-01, 8.8696e-01],\n",
            "        [1.8717e-01, 4.9979e-01, 5.9359e-01, 3.0447e-01, 2.0822e-01, 4.8792e-01,\n",
            "         8.9072e-01, 6.9801e-01, 4.9497e-01, 9.1490e-01, 2.0746e-01, 1.1644e-01,\n",
            "         2.3900e-01, 6.3699e-01, 4.5265e-01, 6.7588e-02, 4.4382e-01, 8.5295e-02,\n",
            "         3.6595e-01, 7.0953e-01, 3.4667e-01, 6.1202e-01, 2.3090e-01, 5.2867e-01,\n",
            "         2.1549e-01, 4.1997e-01, 9.6626e-01, 1.8596e-01],\n",
            "        [3.7623e-01, 3.3931e-01, 8.0724e-01, 5.7298e-01, 5.9126e-01, 6.8245e-01,\n",
            "         3.2377e-04, 6.2505e-03, 5.8734e-01, 7.3834e-01, 3.7567e-01, 6.8222e-01,\n",
            "         6.6220e-01, 3.9420e-01, 7.2322e-01, 7.9118e-01, 2.8724e-01, 3.5593e-01,\n",
            "         4.9901e-01, 1.6232e-01, 4.0259e-01, 3.4475e-01, 9.9464e-01, 8.3044e-01,\n",
            "         6.7265e-01, 4.4363e-01, 4.6605e-02, 7.4846e-01]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand((28,28))\n",
        "print (x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[7.0517e-02, 9.2440e-01, 6.6551e-01, 1.3533e-01, 9.5665e-01, 3.8836e-01,\n",
              "         1.3881e-01, 8.8262e-01, 3.0298e-01, 4.5895e-01, 3.2266e-01, 5.4260e-02,\n",
              "         1.1087e-01, 4.0233e-01, 4.8079e-01, 9.6573e-02, 8.7300e-01, 7.7284e-01,\n",
              "         9.9251e-01, 9.5581e-01, 6.4834e-01, 7.8703e-01, 3.6018e-01, 2.1797e-01,\n",
              "         3.0999e-02, 6.4150e-01, 9.7308e-01, 7.1518e-01, 1.6574e-01, 3.8210e-01,\n",
              "         1.1683e-01, 4.6744e-01, 8.8508e-01, 6.3090e-01, 1.3796e-01, 8.5603e-01,\n",
              "         5.9820e-01, 4.3377e-01, 6.5585e-01, 6.8809e-01, 9.6480e-01, 8.6875e-01,\n",
              "         4.5920e-01, 1.9207e-01, 7.2000e-01, 3.2572e-01, 8.1097e-01, 4.3137e-01,\n",
              "         8.4980e-01, 8.5564e-01, 6.4562e-01, 5.9223e-01, 4.8581e-01, 4.5620e-01,\n",
              "         9.8457e-01, 4.3082e-01, 3.7003e-01, 6.1354e-01, 9.1135e-01, 6.1050e-01,\n",
              "         6.1965e-01, 2.1372e-01, 6.4841e-02, 4.1302e-01, 2.2089e-01, 4.3611e-01,\n",
              "         5.5208e-01, 9.2542e-01, 2.9879e-02, 7.0746e-01, 6.7256e-02, 2.4518e-01,\n",
              "         1.3297e-01, 3.1845e-01, 3.4164e-01, 3.4947e-01, 4.2741e-01, 1.0530e-01,\n",
              "         5.9718e-01, 4.2653e-01, 7.7686e-01, 7.3871e-01, 1.2053e-02, 1.9695e-02,\n",
              "         4.0056e-01, 3.5480e-01, 6.4467e-01, 6.5022e-01, 6.4592e-01, 8.9614e-03,\n",
              "         6.8863e-01, 2.2017e-02, 7.7192e-02, 3.5551e-01, 2.6368e-01, 6.4401e-01,\n",
              "         2.8338e-01, 7.3407e-01, 3.9510e-01, 1.7176e-01, 8.9430e-01, 6.6148e-01,\n",
              "         7.9229e-01, 4.2176e-02, 8.8268e-01, 2.4887e-01, 2.9131e-01, 2.9627e-01,\n",
              "         7.3578e-01, 4.8991e-01, 9.4197e-01, 1.3178e-01, 8.4472e-01, 4.6786e-01,\n",
              "         6.5502e-01, 9.1035e-01, 2.9265e-01, 8.0179e-02, 3.5573e-01, 8.4045e-02,\n",
              "         5.4733e-01, 2.0133e-01, 6.5713e-01, 1.5471e-01, 9.7009e-02, 5.3922e-01,\n",
              "         5.4591e-01, 7.1369e-01, 6.2360e-01, 2.6990e-01, 9.5755e-01, 4.8693e-01,\n",
              "         7.4688e-01, 2.7597e-02, 3.4398e-01, 8.0292e-01, 5.4359e-01, 4.8057e-01,\n",
              "         9.6682e-01, 3.8501e-01, 6.6910e-01, 5.6192e-01, 6.2431e-01, 7.5253e-01,\n",
              "         5.9139e-01, 3.5062e-01, 9.4907e-01, 1.1489e-01, 3.8891e-01, 4.3927e-01,\n",
              "         3.4617e-01, 4.2220e-01, 8.4486e-01, 1.3544e-01, 4.5655e-01, 5.2285e-01,\n",
              "         7.7791e-01, 5.3562e-01, 7.2025e-01, 6.4627e-01, 4.5939e-01, 1.6615e-01,\n",
              "         3.8962e-01, 8.3731e-01, 3.3873e-01, 5.8074e-01, 2.6423e-01, 3.4250e-01,\n",
              "         8.1927e-01, 9.4597e-01, 7.4254e-01, 4.1790e-01, 8.1378e-02, 3.0896e-01,\n",
              "         1.2782e-01, 2.5424e-01, 7.1910e-01, 6.7171e-01, 8.0200e-01, 7.3096e-01,\n",
              "         9.9101e-01, 2.4526e-01, 4.8656e-01, 5.2914e-01, 4.5488e-01, 9.3133e-01,\n",
              "         6.6501e-01, 4.6326e-01, 5.3168e-01, 4.9993e-02, 5.2297e-01, 2.5589e-01,\n",
              "         1.8122e-01, 7.4764e-01, 7.6348e-01, 6.1161e-02, 5.5509e-01, 3.5962e-02,\n",
              "         3.9193e-01, 1.1985e-01, 4.2367e-01, 3.4301e-01, 8.8868e-01, 1.2232e-01,\n",
              "         7.8121e-01, 9.5907e-02, 6.4017e-01, 7.4441e-01, 8.2919e-01, 7.1817e-01,\n",
              "         6.2918e-01, 9.3492e-01, 5.7830e-01, 7.7143e-01, 3.1858e-01, 3.6758e-01,\n",
              "         7.4529e-01, 4.2013e-01, 1.6246e-02, 9.3091e-02, 8.7578e-02, 7.1360e-02,\n",
              "         4.1504e-01, 5.7898e-01, 7.8893e-02, 2.7295e-01, 9.0100e-01, 2.3425e-01,\n",
              "         2.1510e-01, 1.0652e-02, 8.6874e-01, 4.8789e-01, 8.3466e-01, 2.8372e-01,\n",
              "         2.7394e-01, 9.4305e-01, 2.7468e-01, 8.3762e-01, 7.0013e-01, 5.7366e-01,\n",
              "         3.4089e-01, 3.0560e-01, 2.3383e-01, 4.9261e-01, 6.3650e-01, 7.3560e-01,\n",
              "         5.3855e-01, 5.3443e-01, 4.5174e-01, 9.7309e-01, 4.4243e-01, 3.8562e-01,\n",
              "         8.7068e-01, 7.5076e-01, 2.3922e-01, 8.2342e-01, 3.1102e-01, 1.2404e-01,\n",
              "         5.6169e-01, 7.3082e-01, 8.8779e-01, 2.2573e-01, 9.3050e-01, 6.7316e-01,\n",
              "         2.2353e-01, 2.2926e-01, 4.5607e-01, 9.7495e-01, 2.0871e-02, 5.7795e-01,\n",
              "         8.9613e-02, 1.0532e-01, 1.6668e-01, 7.3656e-02, 4.4111e-01, 1.0098e-01,\n",
              "         5.8373e-01, 2.2911e-02, 2.4139e-01, 8.1304e-01, 6.4186e-01, 2.4909e-01,\n",
              "         8.7959e-01, 1.1179e-02, 5.5572e-01, 8.5461e-01, 8.2241e-01, 5.4632e-01,\n",
              "         5.7056e-01, 3.9882e-01, 1.3884e-01, 2.3055e-01, 1.8930e-01, 6.0980e-01,\n",
              "         1.2889e-01, 4.1993e-01, 2.7556e-01, 6.8060e-01, 7.4565e-01, 7.5723e-01,\n",
              "         1.3701e-01, 8.2952e-01, 4.9904e-01, 9.4650e-01, 6.3836e-01, 3.1897e-01,\n",
              "         4.4763e-01, 5.0555e-01, 3.0008e-01, 8.6776e-01, 9.1447e-01, 6.1727e-01,\n",
              "         7.8168e-01, 5.2397e-01, 8.5319e-01, 9.4832e-01, 6.8743e-02, 3.4629e-01,\n",
              "         8.4596e-01, 1.0221e-02, 1.7457e-01, 9.6072e-01, 1.1316e-01, 1.4034e-01,\n",
              "         5.6801e-01, 1.4905e-01, 6.5799e-01, 8.7810e-01, 2.2364e-01, 8.7194e-01,\n",
              "         9.7374e-01, 3.5501e-01, 6.5860e-02, 4.2010e-01, 7.3099e-01, 4.2135e-02,\n",
              "         1.3322e-01, 2.6573e-01, 7.0346e-02, 9.8925e-01, 1.6535e-01, 5.4007e-02,\n",
              "         1.8099e-01, 8.2302e-01, 2.6333e-01, 3.4111e-01, 2.2545e-01, 7.4933e-01,\n",
              "         3.0574e-01, 5.7328e-01, 9.2564e-01, 7.8592e-01, 7.1934e-02, 6.7006e-01,\n",
              "         6.1068e-01, 5.9306e-01, 9.7615e-01, 3.4447e-01, 7.8643e-02, 2.1296e-01,\n",
              "         3.5524e-01, 2.6008e-01, 7.5217e-02, 5.5277e-01, 9.9593e-01, 4.1226e-01,\n",
              "         8.7502e-01, 8.0063e-02, 4.0285e-01, 7.3490e-01, 3.7836e-01, 8.5450e-01,\n",
              "         8.8922e-01, 7.1923e-01, 2.4048e-01, 3.0071e-01, 2.6411e-02, 2.1135e-01,\n",
              "         8.1494e-01, 4.8778e-01, 3.4274e-01, 5.3523e-01, 1.2252e-01, 3.8297e-01,\n",
              "         1.6842e-01, 2.0958e-01, 6.1598e-01, 6.3819e-01, 3.1128e-01, 9.1271e-01,\n",
              "         1.5596e-01, 1.3658e-01, 1.9362e-01, 4.0850e-01, 8.0377e-01, 2.2064e-01,\n",
              "         7.5267e-01, 9.8393e-01, 2.6448e-01, 5.3357e-01, 4.8963e-01, 2.6131e-02,\n",
              "         7.8703e-01, 2.3435e-01, 5.1455e-01, 4.3038e-01, 4.1226e-01, 8.7829e-01,\n",
              "         5.6282e-01, 6.2779e-01, 5.2807e-01, 7.7863e-01, 4.8146e-02, 1.9225e-01,\n",
              "         9.4461e-01, 1.6989e-01, 9.7514e-01, 4.6449e-02, 8.7911e-02, 4.7208e-01,\n",
              "         5.3911e-01, 2.1495e-01, 2.4591e-01, 4.7061e-01, 1.1795e-01, 7.1445e-01,\n",
              "         8.2833e-01, 4.3893e-01, 4.1927e-01, 5.7412e-01, 8.1120e-01, 2.8840e-01,\n",
              "         4.6760e-02, 8.2164e-01, 3.7019e-01, 4.2349e-01, 6.0667e-01, 2.1314e-01,\n",
              "         7.9963e-01, 6.8525e-01, 9.4293e-01, 7.4631e-01, 7.6284e-01, 5.9441e-01,\n",
              "         6.3240e-01, 6.6487e-01, 1.2585e-01, 5.6414e-01, 6.5747e-01, 2.3483e-01,\n",
              "         6.0360e-01, 3.9030e-01, 5.2237e-01, 4.3660e-01, 2.2192e-01, 9.7125e-01,\n",
              "         3.2303e-01, 9.2523e-01, 1.3319e-01, 4.9985e-02, 1.8657e-01, 6.0604e-01,\n",
              "         2.5748e-01, 7.8304e-01, 6.9369e-01, 7.3518e-01, 5.8199e-01, 8.1803e-01,\n",
              "         6.6657e-02, 3.6858e-01, 8.9773e-01, 5.9690e-01, 2.4855e-01, 3.2363e-01,\n",
              "         8.9303e-01, 1.9690e-01, 1.5787e-01, 2.0266e-02, 9.4567e-01, 4.1526e-01,\n",
              "         5.2638e-01, 7.7860e-01, 4.1811e-02, 9.0878e-01, 4.1391e-01, 3.5762e-01,\n",
              "         9.4278e-01, 2.8567e-01, 9.3254e-01, 4.1229e-01, 5.6666e-01, 3.3109e-02,\n",
              "         3.6263e-01, 6.2864e-01, 5.4273e-01, 4.4613e-01, 6.3092e-01, 3.2960e-01,\n",
              "         8.7501e-01, 5.6505e-01, 6.5400e-01, 4.1478e-01, 5.9147e-01, 9.6172e-01,\n",
              "         1.1682e-01, 7.5584e-01, 8.3227e-01, 4.5942e-01, 2.7993e-01, 3.2042e-01,\n",
              "         8.7257e-01, 1.5055e-01, 6.3040e-01, 4.0461e-01, 3.4787e-01, 8.3384e-01,\n",
              "         3.6707e-02, 7.4068e-01, 5.4977e-01, 9.4196e-01, 3.1804e-01, 9.9689e-01,\n",
              "         6.8289e-01, 8.2149e-01, 3.9346e-01, 3.0039e-01, 9.0099e-02, 8.6937e-01,\n",
              "         4.8883e-01, 3.2641e-02, 6.1712e-02, 7.9417e-01, 5.1566e-01, 7.7498e-02,\n",
              "         7.9173e-01, 2.2223e-01, 6.1806e-01, 3.2818e-01, 1.0104e-01, 2.4566e-01,\n",
              "         9.6773e-01, 1.9680e-02, 3.1953e-02, 7.2499e-01, 6.3374e-01, 4.4698e-01,\n",
              "         3.0989e-01, 4.1029e-01, 1.1120e-01, 1.6901e-02, 8.2638e-01, 6.5761e-01,\n",
              "         3.7416e-01, 9.8913e-01, 4.0783e-01, 5.1144e-01, 5.4609e-02, 8.1588e-01,\n",
              "         3.0810e-01, 7.7670e-01, 1.6232e-01, 8.1369e-01, 4.3353e-01, 1.6620e-01,\n",
              "         1.5807e-02, 6.4666e-01, 8.4294e-01, 5.9385e-01, 5.6820e-01, 8.2616e-02,\n",
              "         6.6225e-01, 1.6544e-01, 4.4235e-01, 7.4546e-01, 9.5443e-01, 5.5777e-01,\n",
              "         2.7060e-01, 5.8098e-01, 2.5789e-02, 8.1001e-01, 2.8132e-02, 3.7058e-01,\n",
              "         1.3820e-01, 8.5645e-01, 6.3678e-01, 7.4857e-01, 1.8465e-01, 1.9994e-01,\n",
              "         7.4793e-02, 2.7430e-01, 1.7263e-01, 5.4449e-01, 8.9273e-01, 4.5602e-03,\n",
              "         5.0568e-01, 7.3400e-01, 4.5703e-01, 4.5457e-02, 1.1948e-01, 2.0072e-01,\n",
              "         4.9646e-01, 8.4346e-01, 5.3195e-01, 7.3314e-01, 8.9492e-01, 2.0656e-01,\n",
              "         7.9733e-01, 9.6806e-01, 4.5628e-01, 3.3385e-01, 9.7200e-01, 8.6308e-01,\n",
              "         7.1422e-01, 6.1678e-02, 1.8791e-02, 8.5851e-01, 3.1571e-01, 3.7185e-01,\n",
              "         2.0916e-01, 2.6036e-02, 5.6065e-01, 9.3597e-03, 4.3956e-01, 5.2371e-01,\n",
              "         2.3755e-01, 5.1104e-03, 1.0220e-01, 6.0359e-01, 9.7186e-01, 8.2604e-01,\n",
              "         7.2974e-01, 9.5898e-01, 9.4350e-01, 9.5541e-01, 4.8732e-02, 1.6354e-01,\n",
              "         9.8865e-01, 1.7627e-01, 7.7221e-01, 2.7633e-01, 9.3397e-01, 6.6591e-02,\n",
              "         8.3596e-01, 8.2500e-01, 9.1829e-01, 6.7885e-01, 7.1122e-01, 6.3885e-01,\n",
              "         5.1476e-01, 9.7691e-01, 3.0693e-01, 3.5597e-01, 8.5357e-01, 4.7780e-01,\n",
              "         7.2014e-01, 9.3780e-01, 1.3109e-01, 9.5709e-01, 6.0919e-01, 7.4868e-01,\n",
              "         7.0959e-02, 3.2846e-01, 5.0823e-01, 1.7151e-01, 3.0267e-01, 5.7372e-01,\n",
              "         6.7788e-01, 7.7858e-01, 7.2062e-01, 6.5100e-01, 1.3738e-01, 2.4227e-02,\n",
              "         7.2400e-01, 1.3606e-01, 3.7085e-01, 2.1495e-01, 6.8846e-01, 2.1524e-01,\n",
              "         8.3607e-01, 5.7227e-01, 9.2069e-01, 3.2434e-01, 8.7129e-02, 8.3502e-01,\n",
              "         2.5764e-01, 9.5848e-01, 8.5143e-01, 8.3914e-01, 6.8257e-01, 3.6811e-01,\n",
              "         6.9027e-01, 3.7573e-01, 2.1662e-01, 9.2963e-01, 7.9607e-01, 3.6676e-01,\n",
              "         2.1243e-02, 4.9956e-01, 3.7242e-02, 6.7016e-01, 5.0455e-01, 6.7770e-01,\n",
              "         9.9778e-01, 2.5875e-01, 3.7785e-01, 9.0353e-01, 9.6896e-01, 4.1963e-01,\n",
              "         1.6397e-01, 1.6954e-01, 7.9719e-01, 3.8768e-01, 7.9514e-01, 2.2917e-02,\n",
              "         4.5523e-02, 7.0090e-01, 7.6873e-01, 1.6503e-01, 5.6049e-02, 7.8993e-01,\n",
              "         6.1799e-01, 8.8567e-01, 3.1664e-01, 8.4906e-01, 8.2120e-01, 9.9331e-01,\n",
              "         8.3828e-01, 8.8696e-01, 1.8717e-01, 4.9979e-01, 5.9359e-01, 3.0447e-01,\n",
              "         2.0822e-01, 4.8792e-01, 8.9072e-01, 6.9801e-01, 4.9497e-01, 9.1490e-01,\n",
              "         2.0746e-01, 1.1644e-01, 2.3900e-01, 6.3699e-01, 4.5265e-01, 6.7588e-02,\n",
              "         4.4382e-01, 8.5295e-02, 3.6595e-01, 7.0953e-01, 3.4667e-01, 6.1202e-01,\n",
              "         2.3090e-01, 5.2867e-01, 2.1549e-01, 4.1997e-01, 9.6626e-01, 1.8596e-01,\n",
              "         3.7623e-01, 3.3931e-01, 8.0724e-01, 5.7298e-01, 5.9126e-01, 6.8245e-01,\n",
              "         3.2377e-04, 6.2505e-03, 5.8734e-01, 7.3834e-01, 3.7567e-01, 6.8222e-01,\n",
              "         6.6220e-01, 3.9420e-01, 7.2322e-01, 7.9118e-01, 2.8724e-01, 3.5593e-01,\n",
              "         4.9901e-01, 1.6232e-01, 4.0259e-01, 3.4475e-01, 9.9464e-01, 8.3044e-01,\n",
              "         6.7265e-01, 4.4363e-01, 4.6605e-02, 7.4846e-01]])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = x.view(1,28*28)\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test : Passing information on the untrained Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-2.2204, -2.2263, -2.3658, -2.3726, -2.4189, -2.3653, -2.3511, -2.2946,\n",
              "         -2.2115, -2.2270]], grad_fn=<LogSoftmaxBackward0>)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output = net(x)\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Loss fonction and the Optimizer \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0637, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0241, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0382, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.001 ) #1e-3 also works lr = learning rate\n",
        "\n",
        "#net.parameters() is everything that is ajustable in the model, what the optimizer is going to ajust.\n",
        "\n",
        "EPOCHS = 3 # epoch is when all the data passes tru aour network\n",
        "\n",
        "for epoch in range (EPOCHS):\n",
        "    for data in trainset:\n",
        "        #data is a batch of featuresets and labels\n",
        "        X, y = data\n",
        "        # data is a batch of 10 Tensor of (X) gray pixel values and (y) the numbers \n",
        "        net.zero_grad() # reset the gradients values \n",
        "        output = net(X)\n",
        "        loss = F.nll_loss(output,y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(loss)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "See how correct is the network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.9684\n",
            "correct:  9684\n",
            "total:  10000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# with torch.no_grad(): # this is the test phase so we dont wanna calculate gradient\n",
        "#     for data in testset:\n",
        "#         X, y = data\n",
        "#         output = net(X.view(-1,28*28))\n",
        "#         for idx, i in enumerate (output):\n",
        "#             if torch.argmax(i) == y[idx]:\n",
        "#                 correct += 1\n",
        "#             total += 1\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X, y in testset:\n",
        "        output = net(X)\n",
        "        predicted = torch.argmax(output, dim=1)\n",
        "        correct += (predicted == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "print(\"Accuracy: \", round(correct/total,4))\n",
        "print (\"correct: \",correct)\n",
        "print(\"total: \", total)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(X[4].view(28,28))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(4)\n",
            "tensor(4)\n"
          ]
        }
      ],
      "source": [
        "print(torch.argmax(net(X[4].view(-1,28*28))))\n",
        "print(y[4])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
